---
title: 数据结构——哈希表
date: 2018-12-25 19:59:44
categories: 数据结构
tags:数据结构, 基础
---
hashing(散列法或哈希法)的概念
散列法（Hashing）是一种将字符组成的字符串转换为固定长度（一般是更短长度）的数值或索引值的方法，称为散列法，也叫哈希法。由于通过更短的哈希值比用原始值进行数据库搜索更快，这种方法一般用来在数据库中建立索引并进行搜索，同时还用在各种解密算法中。
HashMap是基于哈希表的Map接口的非同步实现。此实现提供所有可选的映射操作，并允许使用null值和null键。HashMap储存的是键值对，HashMap很快。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。
HashMap实际上是一个“链表散列”的数据结构，即数组和链表的结合体。
数组：存储区间连续，占用内存严重，寻址容易，插入删除困难； 
链表：存储区间离散，占用内存比较宽松，寻址困难，插入删除容易； 
Hashmap综合应用了这两种数据结构，实现了寻址容易，插入删除也容易。 
数据的存储是一个由链表构成的数组，存储数据的元素是Entry类，包含key、value、next（链表的下一个Entry节点）
HashMap整体上性能都非常不错，但是不稳定，为O(N/Buckets)，N就是以数组中没有发生碰撞的元素，Buckets是因碰撞产生的链表，发生碰撞实际上是非常稀少的，所以N/Bucket_size约等于1。
### put操作

```
	final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
		//首先判断table是不是null，是的话则resize
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
		//判断(n - 1) & hash 这个位置是否是null，是的话就新建一个node对象，存入该位置
        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null);
        else {
            Node<K,V> e; K k;
			//判断元素hash值与插入节点hash值是否相等，key是否相同
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;
			//判断元素是否为红黑树节点
            else if (p instanceof TreeNode)
				//直接调用TreeNode方法进行插入
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            else {
				//对node进行循环
                for (int binCount = 0; ; ++binCount) {
					//next节点为空则直接插入
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
						//当前链表长度超过7 则将链表转换为红黑树结构（jdk1.8优化）
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash);
                        break;
                    }
					//已存在该元素的情况
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
				//替换value
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }
```
put操作中最复杂的是构建红黑树的操作，也是就是treeifyBee方法。
```
    final void treeifyBin(Node<K,V>[] tab, int hash) {
        int n, index; Node<K,V> e;
		//MIN_TREEIFY_CAPACITY大小是64，对这个值我的理解是：
		//如果hashMap的容量在这个范围内时，不需要构建红黑树
		//而是直接扩容，因为在一个位置上有多个元素并不是hash值相同，只是与运算结果相同
		//扩容之后重新计算位置，可以使数据更加均匀的分布在数组中，效率更高
        if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
            resize();
        else if ((e = tab[index = (n - 1) & hash]) != null) {
            TreeNode<K,V> hd = null, tl = null;
            do {
				//转化为树节点
                TreeNode<K,V> p = replacementTreeNode(e, null);
				//这里只是把单向链表转换成双向
                if (tl == null)
                    hd = p;
                else {
                    p.prev = tl;
                    tl.next = p;
                }
                tl = p;
            } while ((e = e.next) != null);
            if ((tab[index] = hd) != null)
                hd.treeify(tab);
        }
    }
```
hash算法:
一个优秀的hash算法，需要具备正向快速，逆向困难，输入敏感（修改一点信息会导致hash值不同），冲突敏感（难以找到相同的明文hash值相同）
常见hash算法：MD4、MD5、SHA
而HashMap中的hash算法，是为了让二进制的1更加均匀的混到一起。
```
    static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }
```

### 扩容方法
扩容的基本逻辑：
1.容量大小	如果原来的容量大于0，直接右移一位，容量扩大两倍（如果老容量超出了最大值则直接返回老容量，将threshold赋值为为Integer.MAX_VALUE），如果threshold大于0，就直接把threshold赋值给新的容量，都不满足则设为默认容量。
2.内容复制
创建一个新的Node数组，对老的数组进行循环，，，都不满足则需要循环对应位置链表
```
        if (oldTab != null) {
            for (int j = 0; j < oldCap; ++j) {
                Node<K,V> e;
                if ((e = oldTab[j]) != null) {
                    oldTab[j] = null;
					//如果是只有一个元素的Node则直接怼hash与新的容量运算放入数组中
                    if (e.next == null)
                        newTab[e.hash & (newCap - 1)] = e;
                    else if (e instanceof TreeNode)
						//如果是红黑树，调用TreeNode.split
                        ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                    else { // preserve order
                        Node<K,V> loHead = null, loTail = null;
                        Node<K,V> hiHead = null, hiTail = null;
                        Node<K,V> next;
                        do {
                            next = e.next;
							//这里与运算结果为0不需要移位 下面有具体解释
                            if ((e.hash & oldCap) == 0) {
                                if (loTail == null)
                                    loHead = e;
                                else
                                    loTail.next = e;
                                loTail = e;
                            }
							//需要移位
                            else {
                                if (hiTail == null)
                                    hiHead = e;
                                else
                                    hiTail.next = e;
                                hiTail = e;
                            }
                        } while ((e = next) != null);
                        if (loTail != null) {
                            loTail.next = null;
                            newTab[j] = loHead;
                        }
                        if (hiTail != null) {
                            hiTail.next = null;
                            newTab[j + oldCap] = hiHead;
                        }
                    }
                }
            }
        }
```
这段代码有一段比较不好理解的是对非红黑树链表进行循环时的判断，(e.hash & oldCap) == 0，注意这里要与（e.hash & (newCap - 1)）这个区分开，这个与运算实际是判断元素是否需要移位，大家可以随意试几个hashcode模拟下。原理在于hashMap容量是2的次方，如果低位运算结果是0的话，对于扩容之后的size-1进行与运算的时候还是0，不需要移位。这里也是一个很巧妙的设计。

treeify方法，将链表转化为红黑树。 https://blog.csdn.net/weixin_42340670/article/details/80531795

### ConcurrentHashMap
jdk1.8中，取消了segment分段锁，而采用CAS和synchronized来保证并发安全。数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。
synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生并发，效率又提升N倍。
1.8中比较重要的点：
1.sizeCtl
     hash表初始化或扩容时的一个控制位标识量。
     负数代表正在进行初始化或扩容操作
     -1代表正在初始化
     -N 表示有N-1个线程正在进行扩容操作
     正数或0代表hash表还没有被初始化，这个数值表示初始化或下一次进行扩容的大小
在扩容时，会通过CAS修改sizeCtl的值，用来控制并发。
JDK8中的实现也是锁分离的思想，它把锁分的比segment（JDK1.5）更细一些，只要hash不冲突，就不会出现并发获得锁的情况。它首先使用无锁操作CAS插入头结点，如果插入失败，说明已经有别的线程插入头结点了，再次循环进行操作。如果头结点已经存在，则通过synchronized获得头结点锁，进行后续的操作。性能比segment分段锁又再次提升。
对数据的同步是由volatile修饰Node的next节点、value元素实现。
https://my.oschina.net/pingpangkuangmo/blog/817973

### 有序的HashMap
#### SortedMap
SortedMap是一个有序的 Map 接口，按照自然排序，也可以按照传入的 comparator 进行排序，与 Map 相比，SortedMap 提供了 subMap(K fromKey, K toKey)，headMap(K toKey)，tailMap(K fromKey) 等额外的方法，用于获取与元素顺序相关的值。
#### TreeMap
SortedMap的一种实现，与HashMap不同， TreeMap的底层就是一颗红黑树，它的containsKey , get , put and remove 方法的时间复杂度是 log(n) ，并且它是按照 key 的自然顺序（或者指定排序）排列，与 LinkedHashMap 不同， LinkedHashMap保证了元素是按照插入的顺序排列。
#### LinkedHashMap
LinkedHashMap 拥有 HashMap 的所有特性，它比 HashMap 多维护了一个双向链表，因此可以按照插入的顺序从头部或者从尾部迭代，是有序的，不过因为比 HashMap 多维护了一个双向链表，它的内存相比而言要比 HashMap 大，并且性能会差一些，但是如果需要考虑到元素插入的顺序的话， LinkedHashMap 不失为一种好的选择。

### HashSet
HashSet内部存储数据的就是一个HashMap，不过存入的value是PRESENT，一个默认的Object对象，对存入HashSet的值会作为key存入HashMap，这也是为什么HashSet的数据不能重复。

#### 知识点
在容量为2的次方时，访问性能最高，可以试验下，不为2的次方时进行与运算，会导致大量的空间浪费，增加了碰撞的几率。

question1：
为了满足效率问题，数组的初始容量应该为多少，何时需要扩容？
1.初始容量为1<<4即16
2.当hashmap中的元素个数超过数组大小*loadFactor时

question2：
何时需要将数据存储到链表中，何时储存到数组中？
answer：
对于不同的元素，可能计算出了相同的函数值，这样就产生了“冲突”，这就需要解决冲突，“直接定址”与“解决冲突”是哈希表的两大特点。
对数据存储时会通过哈希函数计算key的hash

question3：
hashcode生成？
System.identityHashCode(obj)。该标识符(理论上)可以用于散列和哈希表之外的其他用途。identityHashCode返回的整数可能与对象的机器地址相关，也可能不是（For current generation JVMs, it is not related to the memory address at all.）。

引申知识点：
1.树、红黑树
https://blog.csdn.net/chen_zhang_yu/article/details/52415077
23树到红黑树的演变，更好的理解左旋转右旋转，变色。
理解红黑树之前，需要先理解二叉查找树，他的特性包括：
	1.左子树上的所有节点的值均小于或等于它的根节点的值。
	2.右子树上的所有节点的值均大于或等于它的根节点的值。
	3.左右子树也分包为二叉排序树。
这样设计的好处在于查找时，先与根节点进行对比，再依次往下对比，这是二分查找的思想，查找所需的最大次数等同于二叉查找树的高度。插入时也是通过同样的方式一层层比较。
但是这样设计存在一个缺陷，如果插入的后续节点都比之前小或者大，会导致层级的快速加深。
红黑树是一种自平衡的二叉查找树，除了符合二叉查找树的基本特性，还包括：
	1.节点是红色或者黑色
	2.根节点是黑色
	3.每个叶子节点都是黑色的空节点（NIL节点）	4.每个红色节点的两个子节点都是黑色即，从叶子到根节点的所有路径上不能有两个连续的红色节点
	5.从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。
	
2.hashcode()，equal、==原理
	hashcode()方法可以被重写，而hashmap调用的hashcode()，实际上调用了identityHashCode(Object)的静态方法不可被重写，为对象提供了一个标识符，该标识符(理论上)可以用于散列和哈希表之外的其他用途。identityHashCode返回的整数可能与对象的(a)机器地址相关，也可能不是（For current generation JVMs, it is not related to the memory address at all.）。identityHashCode()返回的值保证在对象的生命周期内不会更改。https://stackoverflow.com/questions/4930781/how-do-hashcode-and-identityhashcode-work-at-the-back-end

3.位运算
https://baike.baidu.com/item/%E4%BD%8D%E8%BF%90%E7%AE%97%E7%AC%A6/2786163
	1.与运算符
		与运算符用符号“&”表示，两个操作数中位都为1，结果才为1，否则结果为0
	2．或运算符
		或运算符用符号“|”表示，两个位只要有一个为1，那么结果就是1，否则就为0
	3．非运算符
		非运算符用符号“~”表示，如果位为0，结果是1，如果位为1，结果是0
	4．异或运算符
		异或运算符是用符号“^”表示的，两个操作数的位中，相同则结果为0，不同则结果为1
	5.移位运算符
		<<	左移运算符，将运算符左边的对象向左移动运算符右边指定的位数（在低位补0）
		>>	"有符号"右移运算 符，将运算符左边的对象向右移动运算符右边指定的位数。使用符号扩展机制，也就是说，如果值为正，则在高位补0，如果值为负，则在高位补1
		>>>	"无符号"右移运算 符，将运算符左边的对象向右移动运算符右边指定的位数。采用0扩展机制，也就是说，无论值的正负，都在高位补0
4.HashTable、HashMap、ConcurrentHashMap
	HashTable和HashMap的实现原理几乎一样，差别无非是1.HashTable不允许key和value为null；2.HashTable是线程安全的。但是HashTable线程安全的策略实现代价却太大了，简单粗暴，get/put所有相关操作都是synchronized的，这相当于给整个哈希表加了一把大锁，多线程访问时候，只要有一个线程访问或操作该对象，那其他线程只能阻塞，相当于将所有的操作串行化，在竞争激烈的并发场景中性能就会非常差。
	hashtable：index = (hash & 0x7FFFFFFF) % tab.length
	hashMap：index = hash & (tab.length – 1)	ConcurrentHashMap：实现，线程安全通过把整个Map分为N个Segment，可以提供相同的线程安全，但是效率提升N倍，默认提升16倍。(读操作不加锁，由于HashEntry的value变量是volatile的，也能保证读取到最新的值。)Hashtable的synchronized是针对整张Hash表的，即每次锁住整张表让线程独占，ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术有些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁	扩容：段内扩容（段内元素超过该段对应Entry数组长度的75%触发扩容，不会对整个Map进行扩容），插入前检测需不需要扩容，有效避免无效扩容
		
参考资料：
https://www.cnblogs.com/chengxiao/p/6059914.html
https://blog.csdn.net/visant/article/details/80045154
https://www.cnblogs.com/mfmdaoyou/p/6958943.htm